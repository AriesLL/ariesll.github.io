<!doctype html><html lang=en-us>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=generator content="Wowchemy 5.3.0 for Hugo">
<meta name=author content="Peipei Zhou">
<meta name=description content="This dissertation investigates design target, modeling, and optimization for field-programmable gate array (FPGA) customized computing at chip-level, node-level and cluster-level. FPGAs have gained popularity in the acceleration of a wide range of applications with 10x-100x performance/energy efficiency over the general-purpose processors. The design choices of FPGA accelerators for different targets at different levels are enormous. To guide the designers to find the best design choices, modeling is inevitable.

Chip-level performance and energy modeling for embedded and low-power devices. We first study the single chip performance and energy model for FPGA-based pipelined design. Customized pipeline designs that minimize the pipeline initiation interval (II) maximize the throughput of FPGA accelerators designed with high-level synthesis (HLS). However, II>1 can reduce dynamic energy below II=1 due to interconnect savings. We use analytic models to describe accelerator performance and energy, explore the trade-offs of energy and accelerator performance. and find the energy optimal design point.

Chip-level performance and frequency improvement through locality-aware transformation in HLS. We then study timing degradation problems in HLS-based accelerator design and classify four patterns: scatter, gather, broadcast, and reduce in the context of on-chip data movement. We observe that the on-chip data path delay in these patterns scales up when the design size increases, but HLS tools do not estimate the interconnect delay correctly or make a conscientious effort to control or cap the growth of long interconnect delays at the HLS level. We propose a Latte microarchitecture that features pipelined transfer controllers (PTC) to reduce critical path and improves timing by 1.50x on average.

Node-level performance and cost modeling for FPGA-enabled, storage-optimized public cloud instances. At node level, We study performance and cost models for customized computing in light of the fact that performance and cost are primary concerns when deploying applications and services in a pay-as-you-go public cloud. The performance and cost modeling are discussed in two aspects, computation resources, with CPUs and locally PCIe-attached accelerators, and storage resources including SSDs and HDDs.

For computation resources, improved performance using accelerators is accompanied by a higher cost per hour. We discuss the performance and cost modeling of deploying FPGA accelerators, offer insights on accelerator kernel design, and discuss when we should scale up by using FPGA in a node or by choosing a larger instance which has more CPU cores per node. For storage resources, storage systems (SSD/HDD) need to be carefully chosen to match the performance improvement introduced by accelerators while achieving the optimal cost. We conduct quantitative performance analysis on the Spark-based production-quality genome analysis toolkit. We then propose I/O-aware performance analysis and modeling for a broad set of Spark applications. Based on the model, we optimize the cost of genome sequencing in the public cloud by 38%, compared to a configuration recommended by the Spark Official website.

Cluster-level performance and cost modeling for sharing FPGAs among different instances. From a node-level performance and cost model, we learn that simply offloading accelerated kernels from CPU hosts to PCIe-based FPGAs does not guarantee improvement in terms of out-of-pocket cost when using pay-as-you-go services in a public cloud. We analyze the application execution and conclude that the extra cost is attributable to insufficient application-level speedup by Amdahlâ€™s law. To achieve cost saving with the use of FPGA accelerators in the public cloud, we propose to share one FPGA among multiple CPU instances when the number of CPU cores in one instance cannot fully utilize the FPGA accelerator computation resource. By implementing this idea, we present Mocha framework in this dissertation as a distributed runtime system to optimize the out-of-pocket cost while keeping high speedup and throughput.

To demonstrate the performance improvement and cost saving of modeling in customized computing, we use genome pipeline optimization in the public cloud and private cloud as case studies showing how to conduct optimal scheduling under certain constraints. In the public cloud, where cost is the primary concern, we formulate how to select instances and schedule genome stages to achieve the least cost given certain deadline constraints as a MILP (mixed integer linear programming) problem. In a private cloud, where hardware (CPU cores, storage disks) is given, we formulate the scheduling of multiple genomes to achieve the least latency, as a MILP problem.">
<link rel=alternate hreflang=en-us href=https://peipeizhou-eecs.github.io/publication/2019_phd/>
<link rel=preconnect href=https://fonts.gstatic.com crossorigin>
<meta name=theme-color content="#1565c0">
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin=anonymous media=print onload="this.media='all'">
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin=anonymous media=print onload="this.media='all'">
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css crossorigin=anonymous title=hl-light media=print onload="this.media='all'">
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css crossorigin=anonymous title=hl-dark media=print onload="this.media='all'" disabled>
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin=anonymous media=print onload="this.media='all'">
<link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
<link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload="this.media='all'">
<link rel=stylesheet href=/css/wowchemy.f0cf03b20998d63e314819fa4a90c13f.css>
<link rel=manifest href=/manifest.webmanifest>
<link rel=icon type=image/png href=/media/icon_hu1250aaa54d869e747b2648a1402f0494_97654_32x32_fill_lanczos_center_3.png>
<link rel=apple-touch-icon type=image/png href=/media/icon_hu1250aaa54d869e747b2648a1402f0494_97654_180x180_fill_lanczos_center_3.png>
<link rel=canonical href=https://peipeizhou-eecs.github.io/publication/2019_phd/>
<meta property="twitter:card" content="summary">
<meta property="og:site_name" content="Peipei Zhou's Homepage">
<meta property="og:url" content="https://peipeizhou-eecs.github.io/publication/2019_phd/">
<meta property="og:title" content="Modeling and Optimization for Customized Computing: Performance, Energy and Cost Perspective | Peipei Zhou's Homepage">
<meta property="og:description" content="This dissertation investigates design target, modeling, and optimization for field-programmable gate array (FPGA) customized computing at chip-level, node-level and cluster-level. FPGAs have gained popularity in the acceleration of a wide range of applications with 10x-100x performance/energy efficiency over the general-purpose processors. The design choices of FPGA accelerators for different targets at different levels are enormous. To guide the designers to find the best design choices, modeling is inevitable.

Chip-level performance and energy modeling for embedded and low-power devices. We first study the single chip performance and energy model for FPGA-based pipelined design. Customized pipeline designs that minimize the pipeline initiation interval (II) maximize the throughput of FPGA accelerators designed with high-level synthesis (HLS). However, II>1 can reduce dynamic energy below II=1 due to interconnect savings. We use analytic models to describe accelerator performance and energy, explore the trade-offs of energy and accelerator performance. and find the energy optimal design point.

Chip-level performance and frequency improvement through locality-aware transformation in HLS. We then study timing degradation problems in HLS-based accelerator design and classify four patterns: scatter, gather, broadcast, and reduce in the context of on-chip data movement. We observe that the on-chip data path delay in these patterns scales up when the design size increases, but HLS tools do not estimate the interconnect delay correctly or make a conscientious effort to control or cap the growth of long interconnect delays at the HLS level. We propose a Latte microarchitecture that features pipelined transfer controllers (PTC) to reduce critical path and improves timing by 1.50x on average.

Node-level performance and cost modeling for FPGA-enabled, storage-optimized public cloud instances. At node level, We study performance and cost models for customized computing in light of the fact that performance and cost are primary concerns when deploying applications and services in a pay-as-you-go public cloud. The performance and cost modeling are discussed in two aspects, computation resources, with CPUs and locally PCIe-attached accelerators, and storage resources including SSDs and HDDs.

For computation resources, improved performance using accelerators is accompanied by a higher cost per hour. We discuss the performance and cost modeling of deploying FPGA accelerators, offer insights on accelerator kernel design, and discuss when we should scale up by using FPGA in a node or by choosing a larger instance which has more CPU cores per node. For storage resources, storage systems (SSD/HDD) need to be carefully chosen to match the performance improvement introduced by accelerators while achieving the optimal cost. We conduct quantitative performance analysis on the Spark-based production-quality genome analysis toolkit. We then propose I/O-aware performance analysis and modeling for a broad set of Spark applications. Based on the model, we optimize the cost of genome sequencing in the public cloud by 38%, compared to a configuration recommended by the Spark Official website.

Cluster-level performance and cost modeling for sharing FPGAs among different instances. From a node-level performance and cost model, we learn that simply offloading accelerated kernels from CPU hosts to PCIe-based FPGAs does not guarantee improvement in terms of out-of-pocket cost when using pay-as-you-go services in a public cloud. We analyze the application execution and conclude that the extra cost is attributable to insufficient application-level speedup by Amdahlâ€™s law. To achieve cost saving with the use of FPGA accelerators in the public cloud, we propose to share one FPGA among multiple CPU instances when the number of CPU cores in one instance cannot fully utilize the FPGA accelerator computation resource. By implementing this idea, we present Mocha framework in this dissertation as a distributed runtime system to optimize the out-of-pocket cost while keeping high speedup and throughput.

To demonstrate the performance improvement and cost saving of modeling in customized computing, we use genome pipeline optimization in the public cloud and private cloud as case studies showing how to conduct optimal scheduling under certain constraints. In the public cloud, where cost is the primary concern, we formulate how to select instances and schedule genome stages to achieve the least cost given certain deadline constraints as a MILP (mixed integer linear programming) problem. In a private cloud, where hardware (CPU cores, storage disks) is given, we formulate the scheduling of multiple genomes to achieve the least latency, as a MILP problem."><meta property="og:image" content="https://peipeizhou-eecs.github.io/media/icon_hu1250aaa54d869e747b2648a1402f0494_97654_512x512_fill_lanczos_center_3.png">
<meta property="twitter:image" content="https://peipeizhou-eecs.github.io/media/icon_hu1250aaa54d869e747b2648a1402f0494_97654_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us">
<meta property="article:published_time" content="2019-06-10T11:18:19+00:00">
<meta property="article:modified_time" content="2019-06-10T11:18:19+00:00">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://peipeizhou-eecs.github.io/publication/2019_phd/"},"headline":"Modeling and Optimization for Customized Computing: Performance, Energy and Cost Perspective","datePublished":"2019-06-10T11:18:19Z","dateModified":"2019-06-10T11:18:19Z","author":{"@type":"Person","name":"Peipei Zhou"},"publisher":{"@type":"Organization","name":"Peipei Zhou's Homepage","logo":{"@type":"ImageObject","url":"https://peipeizhou-eecs.github.io/media/icon_hu1250aaa54d869e747b2648a1402f0494_97654_192x192_fill_lanczos_center_3.png"}},"description":"This dissertation investigates design target, modeling, and optimization for field-programmable gate array (FPGA) customized computing at chip-level, node-level and cluster-level. FPGAs have gained popularity in the acceleration of a wide range of applications with 10x-100x performance/energy efficiency over the general-purpose processors. The design choices of FPGA accelerators for different targets at different levels are enormous. To guide the designers to find the best design choices, modeling is inevitable.\n\nChip-level performance and energy modeling for embedded and low-power devices. We first study the single chip performance and energy model for FPGA-based pipelined design. Customized pipeline designs that minimize the pipeline initiation interval (II) maximize the throughput of FPGA accelerators designed with high-level synthesis (HLS). However, II\u003e1 can reduce dynamic energy below II=1 due to interconnect savings. We use analytic models to describe accelerator performance and energy, explore the trade-offs of energy and accelerator performance. and find the energy optimal design point.\n\nChip-level performance and frequency improvement through locality-aware transformation in HLS. We then study timing degradation problems in HLS-based accelerator design and classify four patterns: scatter, gather, broadcast, and reduce in the context of on-chip data movement. We observe that the on-chip data path delay in these patterns scales up when the design size increases, but HLS tools do not estimate the interconnect delay correctly or make a conscientious effort to control or cap the growth of long interconnect delays at the HLS level. We propose a Latte microarchitecture that features pipelined transfer controllers (PTC) to reduce critical path and improves timing by 1.50x on average.\n\nNode-level performance and cost modeling for FPGA-enabled, storage-optimized public cloud instances. At node level, We study performance and cost models for customized computing in light of the fact that performance and cost are primary concerns when deploying applications and services in a pay-as-you-go public cloud. The performance and cost modeling are discussed in two aspects, computation resources, with CPUs and locally PCIe-attached accelerators, and storage resources including SSDs and HDDs.\n\nFor computation resources, improved performance using accelerators is accompanied by a higher cost per hour. We discuss the performance and cost modeling of deploying FPGA accelerators, offer insights on accelerator kernel design, and discuss when we should scale up by using FPGA in a node or by choosing a larger instance which has more CPU cores per node. For storage resources, storage systems (SSD/HDD) need to be carefully chosen to match the performance improvement introduced by accelerators while achieving the optimal cost. We conduct quantitative performance analysis on the Spark-based production-quality genome analysis toolkit. We then propose I/O-aware performance analysis and modeling for a broad set of Spark applications. Based on the model, we optimize the cost of genome sequencing in the public cloud by 38%, compared to a configuration recommended by the Spark Official website.\n\nCluster-level performance and cost modeling for sharing FPGAs among different instances. From a node-level performance and cost model, we learn that simply offloading accelerated kernels from CPU hosts to PCIe-based FPGAs does not guarantee improvement in terms of out-of-pocket cost when using pay-as-you-go services in a public cloud. We analyze the application execution and conclude that the extra cost is attributable to insufficient application-level speedup by Amdahlâ€™s law. To achieve cost saving with the use of FPGA accelerators in the public cloud, we propose to share one FPGA among multiple CPU instances when the number of CPU cores in one instance cannot fully utilize the FPGA accelerator computation resource. By implementing this idea, we present Mocha framework in this dissertation as a distributed runtime system to optimize the out-of-pocket cost while keeping high speedup and throughput.\n\nTo demonstrate the performance improvement and cost saving of modeling in customized computing, we use genome pipeline optimization in the public cloud and private cloud as case studies showing how to conduct optimal scheduling under certain constraints. In the public cloud, where cost is the primary concern, we formulate how to select instances and schedule genome stages to achieve the least cost given certain deadline constraints as a MILP (mixed integer linear programming) problem. In a private cloud, where hardware (CPU cores, storage disks) is given, we formulate the scheduling of multiple genomes to achieve the least latency, as a MILP problem."}</script>
<title>Modeling and Optimization for Customized Computing: Performance, Energy and Cost Perspective | Peipei Zhou's Homepage</title>
</head>
<body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=126abc48a4a1b5e5269b8f38857877be>
<script src=/js/wowchemy-init.min.8988fb2a4bba758785868cfcb5244555.js></script>
<aside class=search-modal id=search>
<div class=container>
<section class=search-header>
<div class="row no-gutters justify-content-between mb-3">
<div class=col-6>
<h1>Search</h1>
</div>
<div class="col-6 col-search-close">
<a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a>
</div>
</div>
<div id=search-box>
<input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...>
</div>
</section>
<section class=section-search-results>
<div id=search-hits>
</div>
</section>
</div>
</aside>
<div class=page-header>
<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main>
<div class=container-xl>
<div class="d-none d-lg-inline-flex">
<a class=navbar-brand href=/>Peipei Zhou's Homepage</a>
</div>
<button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span>
</button>
<div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
<a class=navbar-brand href=/>Peipei Zhou's Homepage</a>
</div>
<div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content>
<ul class="navbar-nav d-md-inline-flex">
<li class=nav-item>
<a class=nav-link href=/#about><span>Home</span></a>
</li>
<li class=nav-item>
<a class="nav-link active" href=/publication><span>Publications</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#posts><span>Posts</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#accomplishments><span>Honor</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/uploads/Peipei_Zhou_CV.pdf><span>CV</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#experience><span>Career</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#projects><span>Projects</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/people><span>People</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#talks><span>Talks</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#contact><span>Contact</span></a>
</li>
</ul>
</div>
<ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
<li class=nav-item>
<a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a>
</li>
<li class="nav-item dropdown theme-dropdown">
<a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences">
<i class="fas fa-moon" aria-hidden=true></i>
</a>
<div class=dropdown-menu>
<a href=# class="dropdown-item js-set-theme-light">
<span>Light</span>
</a>
<a href=# class="dropdown-item js-set-theme-dark">
<span>Dark</span>
</a>
<a href=# class="dropdown-item js-set-theme-auto">
<span>Automatic</span>
</a>
</div>
</li>
</ul>
</div>
</nav>
</div>
<div class=page-body>
<div class=pub>
<div class="article-container pt-3">
<h1>Modeling and Optimization for Customized Computing: Performance, Energy and Cost Perspective</h1>
<div class=article-metadata>
<div>
<span class=author-highlighted>
<a href=/author/peipei-zhou/>Peipei Zhou</a></span>
</div>
<span class=article-date>
June 2019
</span>
</div>
<div class="btn-links mb-3">
<a href=# class="btn btn-outline-primary btn-page-header js-cite-modal" data-filename=/publication/2019_phd/cite.bib>
Cite
</a>
<a class="btn btn-outline-primary btn-page-header" href=https://escholarship.org/uc/item/6g7663zw target=_blank rel=noopener>
PDF
</a>
<a class="btn btn-outline-primary btn-page-header" href=https://peipeizhou-eecs.github.io/uploads/slides/Defense_PeipeiZhou_20190610.pptx target=_blank rel=noopener>
Slides
</a>
<a class="btn btn-outline-primary btn-page-header" href="https://www.youtube.com/watch?v=NJNAYbGYvm4" target=_blank rel=noopener>
<i class="fab fa-youtube mr-1"></i>
Video
</a>
</div>
</div>
<div class=article-container>
<h3>Abstract</h3>
<p class=pub-abstract><p>This dissertation investigates design target, modeling, and optimization for field-programmable gate array (FPGA) customized computing at chip-level, node-level and cluster-level. FPGAs have gained popularity in the acceleration of a wide range of applications with 10x-100x performance/energy efficiency over the general-purpose processors. The design choices of FPGA accelerators for different targets at different levels are enormous. To guide the designers to find the best design choices, modeling is inevitable.</p>
<p>Chip-level performance and energy modeling for embedded and low-power devices. We first study the single chip performance and energy model for FPGA-based pipelined design. Customized pipeline designs that minimize the pipeline initiation interval (II) maximize the throughput of FPGA accelerators designed with high-level synthesis (HLS). However, II>1 can reduce dynamic energy below II=1 due to interconnect savings. We use analytic models to describe accelerator performance and energy, explore the trade-offs of energy and accelerator performance. and find the energy optimal design point.</p>
<p>Chip-level performance and frequency improvement through locality-aware transformation in HLS. We then study timing degradation problems in HLS-based accelerator design and classify four patterns: scatter, gather, broadcast, and reduce in the context of on-chip data movement. We observe that the on-chip data path delay in these patterns scales up when the design size increases, but HLS tools do not estimate the interconnect delay correctly or make a conscientious effort to control or cap the growth of long interconnect delays at the HLS level. We propose a Latte microarchitecture that features pipelined transfer controllers (PTC) to reduce critical path and improves timing by 1.50x on average.</p>
<p>Node-level performance and cost modeling for FPGA-enabled, storage-optimized public cloud instances. At node level, We study performance and cost models for customized computing in light of the fact that performance and cost are primary concerns when deploying applications and services in a pay-as-you-go public cloud. The performance and cost modeling are discussed in two aspects, computation resources, with CPUs and locally PCIe-attached accelerators, and storage resources including SSDs and HDDs.</p>
<p>For computation resources, improved performance using accelerators is accompanied by a higher cost per hour. We discuss the performance and cost modeling of deploying FPGA accelerators, offer insights on accelerator kernel design, and discuss when we should scale up by using FPGA in a node or by choosing a larger instance which has more CPU cores per node. For storage resources, storage systems (SSD/HDD) need to be carefully chosen to match the performance improvement introduced by accelerators while achieving the optimal cost. We conduct quantitative performance analysis on the Spark-based production-quality genome analysis toolkit. We then propose I/O-aware performance analysis and modeling for a broad set of Spark applications. Based on the model, we optimize the cost of genome sequencing in the public cloud by 38%, compared to a configuration recommended by the Spark Official website.</p>
<p>Cluster-level performance and cost modeling for sharing FPGAs among different instances. From a node-level performance and cost model, we learn that simply offloading accelerated kernels from CPU hosts to PCIe-based FPGAs does not guarantee improvement in terms of out-of-pocket cost when using pay-as-you-go services in a public cloud. We analyze the application execution and conclude that the extra cost is attributable to insufficient application-level speedup by Amdahlâ€™s law. To achieve cost saving with the use of FPGA accelerators in the public cloud, we propose to share one FPGA among multiple CPU instances when the number of CPU cores in one instance cannot fully utilize the FPGA accelerator computation resource. By implementing this idea, we present Mocha framework in this dissertation as a distributed runtime system to optimize the out-of-pocket cost while keeping high speedup and throughput.</p>
<p>To demonstrate the performance improvement and cost saving of modeling in customized computing, we use genome pipeline optimization in the public cloud and private cloud as case studies showing how to conduct optimal scheduling under certain constraints. In the public cloud, where cost is the primary concern, we formulate how to select instances and schedule genome stages to achieve the least cost given certain deadline constraints as a MILP (mixed integer linear programming) problem. In a private cloud, where hardware (CPU cores, storage disks) is given, we formulate the scheduling of multiple genomes to achieve the least latency, as a MILP problem.</p>
</p>
<div class=row>
<div class=col-md-1></div>
<div class=col-md-10>
<div class=row>
<div class="col-12 col-md-3 pub-row-heading">Type</div>
<div class="col-12 col-md-9">
<a href=/publication/#7>
Thesis
</a>
</div>
</div>
</div>
<div class=col-md-1></div>
</div>
<div class="d-md-none space-below"></div>
<div class=row>
<div class=col-md-1></div>
<div class=col-md-10>
<div class=row>
<div class="col-12 col-md-3 pub-row-heading">Publication</div>
<div class="col-12 col-md-9">UCLA Electronic Theses and Dissertations</div>
</div>
</div>
<div class=col-md-1></div>
</div>
<div class="d-md-none space-below"></div>
<div class=space-below></div>
<div class=article-style></div>
<div class=article-tags>
<a class="badge badge-light" href=/tag/thesis/>Thesis</a>
</div>
<div class=share-box aria-hidden=true>
<ul class=share>
<li>
<a href="https://twitter.com/intent/tweet?url=https://peipeizhou-eecs.github.io/publication/2019_phd/&text=Modeling%20and%20Optimization%20for%20Customized%20Computing:%20Performance,%20Energy%20and%20Cost%20Perspective" target=_blank rel=noopener class=share-btn-twitter>
<i class="fab fa-twitter"></i>
</a>
</li>
<li>
<a href="https://www.facebook.com/sharer.php?u=https://peipeizhou-eecs.github.io/publication/2019_phd/&t=Modeling%20and%20Optimization%20for%20Customized%20Computing:%20Performance,%20Energy%20and%20Cost%20Perspective" target=_blank rel=noopener class=share-btn-facebook>
<i class="fab fa-facebook"></i>
</a>
</li>
<li>
<a href="mailto:?subject=Modeling%20and%20Optimization%20for%20Customized%20Computing:%20Performance,%20Energy%20and%20Cost%20Perspective&body=https://peipeizhou-eecs.github.io/publication/2019_phd/" target=_blank rel=noopener class=share-btn-email>
<i class="fas fa-envelope"></i>
</a>
</li>
<li>
<a href="https://www.linkedin.com/shareArticle?url=https://peipeizhou-eecs.github.io/publication/2019_phd/&title=Modeling%20and%20Optimization%20for%20Customized%20Computing:%20Performance,%20Energy%20and%20Cost%20Perspective" target=_blank rel=noopener class=share-btn-linkedin>
<i class="fab fa-linkedin-in"></i>
</a>
</li>
<li>
<a href="whatsapp://send?text=Modeling%20and%20Optimization%20for%20Customized%20Computing:%20Performance,%20Energy%20and%20Cost%20Perspective%20https://peipeizhou-eecs.github.io/publication/2019_phd/" target=_blank rel=noopener class=share-btn-whatsapp>
<i class="fab fa-whatsapp"></i>
</a>
</li>
<li>
<a href="https://service.weibo.com/share/share.php?url=https://peipeizhou-eecs.github.io/publication/2019_phd/&title=Modeling%20and%20Optimization%20for%20Customized%20Computing:%20Performance,%20Energy%20and%20Cost%20Perspective" target=_blank rel=noopener class=share-btn-weibo>
<i class="fab fa-weibo"></i>
</a>
</li>
</ul>
</div>
<div class="media author-card content-widget-hr">
<a href=https://peipeizhou-eecs.github.io/><img class="avatar mr-3 avatar-circle" src=/author/peipei-zhou/avatar_hu80b7558909def6d2fb092cd7f28877cb_2616395_270x270_fill_q75_lanczos_center.jpg alt="Peipei Zhou"></a>
<div class=media-body>
<h5 class=card-title><a href=https://peipeizhou-eecs.github.io/>Peipei Zhou</a></h5>
<h6 class=card-subtitle>Assistant Professor of ECE Department</h6>
<p class=card-text>My research interests include <strong>Customized Computer Architecture and Programming Abstraction for Health & AI Applications</strong></p>
<ul class=network-icon aria-hidden=true>
<li>
<a href="https://scholar.google.com/citations?user=px_jwFgAAAAJ&hl=en" target=_blank rel=noopener>
<i class="ai ai-google-scholar"></i>
</a>
</li>
<li>
<a href=https://www.linkedin.com/in/zhoupeipei/ target=_blank rel=noopener>
<i class="fab fa-linkedin"></i>
</a>
</li>
<li>
<a href=https://twitter.com/PeipeiZhou_EECS target=_blank rel=noopener>
<i class="fab fa-twitter"></i>
</a>
</li>
<li>
<a href=https://github.com/AriesLL target=_blank rel=noopener>
<i class="fab fa-github"></i>
</a>
</li>
</ul>
</div>
</div>
<div class="article-widget content-widget-hr">
<h3>Related</h3>
<ul>
<li><a href=/publication/2014_master/>A Fully Pipelined and Dynamically Composable Architecture of CGRA (Coarse Grained Reconfigurable Architecture)</a></li>
</ul>
</div>
</div>
</div>
</div>
<div class=page-footer>
<div class=container>
<footer class=site-footer>
<p class=powered-by>
Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> â€” the free, <a href=https://github.com/wowchemy/wowchemy-hugo-modules target=_blank rel=noopener>open source</a> website builder that empowers creators.
</p>
</footer>
</div>
</div>
<div id=modal class="modal fade" role=dialog>
<div class=modal-dialog>
<div class=modal-content>
<div class=modal-header>
<h5 class=modal-title>Cite</h5>
<button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span>
</button>
</div>
<div class=modal-body>
<pre><code class="tex hljs"></code></pre>
</div>
<div class=modal-footer>
<a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank>
<i class="fas fa-copy"></i> Copy
</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank>
<i class="fas fa-download"></i> Download
</a>
<div id=modal-error></div>
</div>
</div>
</div>
</div>
<script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin=anonymous></script>
<script id=search-hit-fuse-template type=text/x-template>
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin=anonymous></script>
<script src=/js/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js></script>
<script src=/en/js/wowchemy.min.d68ecd57c0ec1f1f61d65fd568f1c3a0.js></script>
<div align=center>You are the No. <a href=https://www.counter12.com><img src=https://www.counter12.com/img-49xzY0AA307xy64z-50.gif border=0 alt="free counter"></a> vistor of my research homepage at Pitt-ECE.<script type=text/javascript src="https://www.counter12.com/ad.js?id=49xzY0AA307xy64z"></script></div>
<script type=text/javascript>var sc_project=12584110,sc_invisible=1,sc_security="ae6d8e6b",scJsHost="https://";document.write("<script type='text/javascript' src='"+scJsHost+"statcounter.com/counter/counter.js'></"+"script>")</script>
<noscript><div class=statcounter><a title="Web Analytics
Made Easy - StatCounter" href=https://statcounter.com/ target=_blank><img class=statcounter src=https://c.statcounter.com/12584110/0/ae6d8e6b/0/ alt="Web Analytics Made Easy - StatCounter" referrerpolicy=no-referrer-when-downgrade></a></div></noscript>
</body>
</html>